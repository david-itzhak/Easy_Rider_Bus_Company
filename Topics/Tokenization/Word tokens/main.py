from nltk import word_tokenize

text = input()
tokenized_copy_of_text = word_tokenize(text)
print(tokenized_copy_of_text)